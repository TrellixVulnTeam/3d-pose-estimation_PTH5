{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "    \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "    Puts image into numpy array to feed into tensorflow graph.\n",
    "    Note that by convention we put it into a numpy array with shape\n",
    "    (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "    Args:\n",
    "    path: the file path to the image\n",
    "\n",
    "    Returns:\n",
    "    uint8 numpy array with shape (1, img_height, img_width, 3)\n",
    "    \"\"\"\n",
    "    img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "    image = Image.open(BytesIO(img_data))\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (1, im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "def visualize_bboxes(image_np, detection_result):\n",
    "    scores = detection_result['detection_scores'][0]\n",
    "    boxes = detection_result['detection_boxes'][0]\n",
    "    labels = detection_result['detection_classes'][0]\n",
    "\n",
    "    person_scores = scores * [label == 1 for label in labels]\n",
    "    boxes = [box for i, box in enumerate(boxes) if scores[i] > 0.5]\n",
    "\n",
    "    # For demo only:\n",
    "    fig,ax = plt.subplots(1)\n",
    "    ax.imshow(image_np[0])\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "        x1 *= image_np.shape[1]\n",
    "        x2 *= image_np.shape[1]\n",
    "        y1 *= image_np.shape[2]\n",
    "        y2 *= image_np.shape[2]\n",
    "\n",
    "        rect = patches.Rectangle((y1,x1),y2-y1,x2-x1,linewidth=1,edgecolor='r',facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Model from the Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model...\n",
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "print('loading model...')\n",
    "model = hub.load(\"https://tfhub.dev/tensorflow/efficientdet/d4/1\")\n",
    "print('model loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load label map data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map_path = 'object_detection/data/mscoco_label_map.pbtxt'\n",
    "label_map = label_map_util.load_labelmap(label_map_path)\n",
    "categories = label_map_util.convert_label_map_to_categories(\n",
    "    label_map,\n",
    "    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n",
    "    use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)\n",
    "\n",
    "PERSON_LABEL = label_map_dict['person']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer BB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferBoundingBox(image_path: str):\n",
    "    image_np = load_image_into_numpy_array(image_path)\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(\n",
    "        np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
    "    \n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-dbf0093462c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_filename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_filenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mimage_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image_into_numpy_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-d09389ba93d2>\u001b[0m in \u001b[0;36mload_image_into_numpy_array\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mim_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_height\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     return np.array(image.getdata()).reshape(\n\u001b[0m\u001b[1;32m     18\u001b[0m         (1, im_height, im_width, 3)).astype(np.uint8)\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pjoin = os.path.join\n",
    "fexists = os.path.exists\n",
    "\n",
    "outfile = 'efficient-bb.npz'\n",
    "\n",
    "image_dir = '/root/data/images'\n",
    "subjects = ['S1', 'S5', 'S6', 'S7', 'S8', 'S9', 'S11']\n",
    "cameras = ['54138969', '55011271', '58860488', '60457274']\n",
    "\n",
    "for subject in subjects:\n",
    "    actions = os.listdir(pjoin(image_dir, subject))\n",
    "    for action in actions:\n",
    "        if fexists(pjoin(image_dir, subject, action, outfile)):\n",
    "            continue\n",
    "        bbs = {camera: [] for camera in cameras}\n",
    "        for camera in cameras:\n",
    "            images_filenames = os.listdir(pjoin(image_dir, subject, action, 'imageSequence', camera))\n",
    "            images_paths = [pjoin(image_dir, subject, action, 'imageSequence', camera, f) for f in images_filenames]\n",
    "            \n",
    "            for image_path, image_filename in zip(images_paths, images_filenames):\n",
    "                image_np = load_image_into_numpy_array(image_path)\n",
    "                results = model(image_np)\n",
    "                result = {key:value.numpy() for key,value in results.items()}\n",
    "                \n",
    "                scores = result['detection_scores'][0]\n",
    "                boxes = result['detection_boxes'][0]\n",
    "                labels = result['detection_classes'][0]\n",
    "                \n",
    "                person_scores = scores * [label == PERSON_LABEL for label in labels]\n",
    "                person_boxes = [box for i, box in enumerate(boxes) if scores[i] > 0.5]\n",
    "                \n",
    "                # For demo only:\n",
    "                # visualize_bboxes(image_np, result)\n",
    "                \n",
    "                bbs[camera].append({\n",
    "                    'image': image_filename,\n",
    "                    'scores': [score for score in person_scores if score > 0.5],\n",
    "                    'boxes': person_boxes\n",
    "                })\n",
    "                pass\n",
    "            pass\n",
    "        \n",
    "        np.savez(pjoin(image_dir, subject, action, outfile), data=bbs)\n",
    "        print('Saving: {}'.format(pjoin(image_dir, subject, action, outfile)))\n",
    "        pass\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
